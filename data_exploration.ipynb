{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from twarc.client2 import Twarc2\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "# Setup environment\n",
    "load_dotenv()\n",
    "BEARER_TOKEN = os.getenv('BEARER_TOKEN')\n",
    "API_KEY = os.getenv('API_KEY')  # cosumer_key\n",
    "API_KEY_SECRET = os.getenv('API_KEY_SECRET')  # consumer_secret\n",
    "ACCESS_TOKEN = os.getenv('ACCESS_TOKEN')\n",
    "ACCESS_TOKEN_SECRET = os.getenv('ACCESS_TOKEN_SECRET')\n",
    "MY_ID = os.getenv('MY_ID')\n",
    "\n",
    "# Setup client\n",
    "t = Twarc2(consumer_key=API_KEY, consumer_secret=API_KEY_SECRET,\n",
    "           access_token=ACCESS_TOKEN, access_token_secret=ACCESS_TOKEN_SECRET,\n",
    "           bearer_token=BEARER_TOKEN, )\n",
    "\n",
    "\n",
    "def fetch_twitter_data() -> list:\n",
    "    \"\"\"\n",
    "    Uses the twarc library to obtain data of the people I follow.\n",
    "    \"\"\"\n",
    "    users_i_follow = []\n",
    "    data_generator = t.following(user=MY_ID)\n",
    "\n",
    "    # Use generator to repeatedly get the next list of users:\n",
    "    for obj in data_generator:\n",
    "        users_i_follow.extend(obj['data']) if 'data' in obj.keys() \\\n",
    "            else users_i_follow.extend(obj['errors'])\n",
    "\n",
    "    return users_i_follow\n",
    "\n",
    "\n",
    "def get_dataframes() -> tuple:\n",
    "    \"\"\"\n",
    "    This function obtains the data of interest, puts it into\n",
    "    two pd.DataFrames, and returns a tuple like so:\n",
    "    (today: pd.DataFrame, yesterday: pd.DataFrame)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize dates we will use:\n",
    "    today = datetime.strftime(datetime.today(), '%b-%-d-%Y')\n",
    "    yesterday = datetime.strftime((datetime.today() + timedelta(days=-1)), '%b-%-d-%Y')\n",
    "    two_days_ago = datetime.strftime((datetime.today() + timedelta(days=-2)), '%b-%-d-%Y')\n",
    "\n",
    "    # Get twitter data and save to csv, this is today's df\n",
    "    # following_today = fetch_twitter_data()\n",
    "    # todays_data = pd.json_normalize(following_today)\n",
    "    # todays_data.to_csv(f'static/{today}.csv')\n",
    "\n",
    "    # From disk:\n",
    "    todays_data = pd.read_csv(f'static/{today}.csv')\n",
    "\n",
    "    # Read yesterday's df from file:\n",
    "    yesterdays_data = pd.read_csv(f'static/{yesterday}.csv')\n",
    "\n",
    "    # Remove file from two days ago if it exists:\n",
    "    # FIXME: Ok to uncomment when ready to launch:\n",
    "    # try:\n",
    "    #     os.remove(f'static/{two_days_ago}.csv')\n",
    "    # except FileNotFoundError:\n",
    "    #     pass\n",
    "\n",
    "    return todays_data, yesterdays_data\n",
    "\n",
    "\n",
    "\n",
    "def plant_bad_seed(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function was created as a sanity check. I wanted to\n",
    "    write a function to plant a difference and see what\n",
    "    happens to the behavior of the `is_following_list_identical()` function.\n",
    "    \"\"\"\n",
    "    bad_seed = {\n",
    "        'description': ['some test person'],\n",
    "        'name': ['john doe'],\n",
    "        'location': ['somewhere idk'],\n",
    "        'profile_image_url': ['https://picsum.photos/id/237/200/300'],\n",
    "        'url': [''],\n",
    "        'verified': [False],\n",
    "        'protected': [False],\n",
    "        'id': ['666'],\n",
    "        'username': ['jd'],\n",
    "        'created_at': [datetime.now()],\n",
    "    }\n",
    "    bad_df = pd.DataFrame(bad_seed)\n",
    "    return pd.concat([df, bad_df], ignore_index=True, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def is_following_list_identical(todays_df: pd.DataFrame, yesterdays_df: pd.DataFrame) -> tuple:\n",
    "    # Default data contains a lot of extra columns, so they are dropped:\n",
    "    extra_columns = ['entities.url.urls', 'entities.description.urls',\n",
    "                     'public_metrics.followers_count', 'public_metrics.following_count',\n",
    "                     'public_metrics.tweet_count', 'public_metrics.listed_count',\n",
    "                     'entities.description.hashtags', 'entities.description.mentions',\n",
    "                     'pinned_tweet_id', 'entities.description.cashtags',\n",
    "                     ]\n",
    "    todays_df.drop(columns=extra_columns, inplace=True)\n",
    "    yesterdays_df.drop(columns=extra_columns, inplace=True)\n",
    "\n",
    "    if 'Unnamed: 0' in todays_df.columns:\n",
    "        todays_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    if 'Unnamed: 0' in yesterdays_df.columns:\n",
    "        yesterdays_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    # Renaming this column to distinguish it from index.\n",
    "    renamed_columns = ({'id': 'user_id'})\n",
    "    todays_df.rename(columns=renamed_columns, inplace=True)\n",
    "    yesterdays_df.rename(columns=renamed_columns, inplace=True)\n",
    "\n",
    "    # Cast user_id column type as `int64` type is not guaranteed. The column\n",
    "    # datatype changes depending on if we read it from a file or not.\n",
    "    todays_df[['user_id']] = todays_df[['user_id']].apply(pd.to_numeric, errors='coerce')\n",
    "    yesterdays_df[['user_id']] = yesterdays_df[['user_id']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # To find differences that exist in either dataframe, we use\n",
    "    # something called a \"symmetric difference\" between two sets.\n",
    "    # We can assume each user_id is unique, so that's what we use for comparison.\n",
    "    # https://www.adamsmith.haus/python/answers/how-to-get-the-symmetric-difference-of-pandas-dataframes-in-python\n",
    "    union = pd.concat([todays_df, yesterdays_df], axis=0)\n",
    "    sym_diff = union.drop_duplicates(subset='user_id', keep=False, inplace=False)\n",
    "\n",
    "    yesterday_only = pd.merge(left=yesterdays_df, right=todays_df, how='left', on='user_id', indicator=True)\n",
    "    yesterday_only = yesterday_only[yesterday_only['_merge'] == 'left_only']\n",
    "\n",
    "    today_only = pd.merge(left=todays_df, right=yesterdays_df, how='left', on='user_id', indicator=True)\n",
    "    today_only = today_only[today_only['_merge'] == 'left_only']\n",
    "\n",
    "    no_diff = len(sym_diff) == 0  # if empty, there are no differences\n",
    "    if no_diff:\n",
    "        return False, yesterday_only, today_only, sym_diff\n",
    "    else:\n",
    "        return True, yesterday_only, today_only, sym_diff\n",
    "\n",
    "\n",
    "td_df, yd_df = get_dataframes()\n",
    "# td_df = plant_bad_seed(td_df)  # use to test\n",
    "yd_df = plant_bad_seed(yd_df)  # use to test\n",
    "results = is_following_list_identical(todays_df=td_df, yesterdays_df=yd_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "     url  user_id      name username                     profile_image_url  \\\n1855          666  john doe       jd  https://picsum.photos/id/237/200/300   \n\n                      created_at  protected       description  verified  \\\n1855  2022-04-10 13:09:14.700626      False  some test person     False   \n\n           location  \n1855  somewhere idk  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>user_id</th>\n      <th>name</th>\n      <th>username</th>\n      <th>profile_image_url</th>\n      <th>created_at</th>\n      <th>protected</th>\n      <th>description</th>\n      <th>verified</th>\n      <th>location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1855</th>\n      <td></td>\n      <td>666</td>\n      <td>john doe</td>\n      <td>jd</td>\n      <td>https://picsum.photos/id/237/200/300</td>\n      <td>2022-04-10 13:09:14.700626</td>\n      <td>False</td>\n      <td>some test person</td>\n      <td>False</td>\n      <td>somewhere idk</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}